\documentclass[12pt]{article}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb, amsmath}
\usepackage{fullpage}

\usepackage{times}
\usepackage{courier}
\usepackage{minted}

\setcounter{secnumdepth}{0} % supresss section numbers

\title{Process Local Aggregation in MapReduce}
\author{Josh Rosen}

\begin{document}
\maketitle

In current versions of Spark, \texttt{reduceByKey} shuffles
$O(\text{numMapPartitions} * \text{numReducers})$ blocks over the network.  In
most cases, it would be more efficient to perform a process-local reduction of
all of the blocks processed by a particular worker, since this may
drastically reduce the amount of data we need to shuffle.

Currently, \texttt{reduceByKey} performance can degrade when a large number of
map partitions are used: we may transfer $O(\text{numMapPartitions}
* \text{numReducePartitions})$ blocks when, ideally, we could transfer only
$O(\text{numMappers} * \text{numReducePartitions})$.

Large numbers of map tasks also cause problems for disk-based shuffles: disk
performance can rapidly degrade if the reduce phase causes many seeks on the
mappers' disks.

These problems are barriers to efficiently supporting tiny tasks as
a skew-mitigation and load-balancing technique \cite{tinytasks}.

Fault-tolerance is the main difficulty in fixing these problems: correct
solutions need to handle failing map and reduce tasks and properly handle
output from speculative tasks.

\section{Existing Solutions and Proposals}

There have been multiple proposals to solve these problems in Hadoop and Spark.

Sailfish \cite{sailfish} introduces an
abstraction that allows map outputs from multiple writers to be batched
together on disk based on which reducer will process them.  Their
$\mathcal{I}$-files abstraction also allows the number of reducers to be
determined between the map and reduce phases by maintaining indices to support
efficient retrieval of key ranges.

For Spark, \texttt{SPARK-751} \cite{SPARK-751} proposes a scheme where shuffle block
writers are shared between multiple map tasks, and on-disk files store the
concatenated output of multiple map tasks.  Within each file, map outputs are
tagged with map identifiers and sequence numbers that allow reducers to skip
duplicated data and ignore output from tasks that did not successfully
register their completion with the master node .  The on-disk files implement
an atomic append operation that flushes and truncates the files to clean up
partial writes from failed mappers.

For Hadoop, \texttt{MAPREDUCE-4502} \cite{MR-4502} is a proposal to add
node-level aggregation, which is implemented by having one map task per node
act as a machine-local aggregator.  Completed non-aggregator map tasks
communicate with the application master to discover aggregator tasks.

Sailfish has been implemented, but these other approaches have not been
integrated into their respective codebases.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{My Proposal}

\subsection{Keeping Map Outputs in Memory}

Hadoop saves its map outputs to HDFS for fault-tolerance.

Spark currently writes its serialized shuffle outputs to disk to reduce the
cost of recomputing shuffled RDDs and to reduce memory usage.  In principle,
this is inexpensive because the shuffle outputs may remain in OS buffer cache
long enough to be read by reducers, but this data will eventually have to hit
disk; this could be a bottleneck in shuffle-intensive workloads.

Instead, we could move this buffering into Spark, allowing us to exert more
control over when and how this data is flushed to disk.  For example, shuffle
blocks could be cached in the BlockStore by default, being spilled to disk
only when memory is needed.

When selecting a victim to spill to disk, the BlockStore can use its knowledge
of shuffle access patterns to make good eviction decisions.  Once a shuffle
block has been read, it won't be re-read unless a reducer fails.  When
a BlockStore is asked to store a number of shuffle blocks, it may infer that
a shuffle phase is being performed and that many accesses will be to shuffle
blocks.  Finally, non-dirty disk-resident blocks can be evicted without
performing disk writes. Combining these ideas, we can use the following
heuristic eviction order:

\begin{itemize}
        \item Shuffle blocks that have already been sent
        \item Any blocks that are already on disk
        \item Shuffle blocks received but not yet processed
        \item Shuffle blocks that have not been sent
        \item Non-shuffle blocks, using the regular LRU eviction policy
\end{itemize}

To improve this approach, we can use a background cleaner thread that
proactively flushes blocks to disk.  Whenever a shuffle block has been sent,
it can immediately be dropped to disk.  We could extend this approach to
continuously flush cached datasets to disk as long as there's free disk
bandwidth to allow for quick eviction of cached datasets (and disk-based
fault-tolerance).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Machine-Local Pre-Aggregation}

To reduce the volume of data that needs to be shuffled, we can pre-aggregate
all of the outputs produced on each node.  A good implementation of this
should allow for flexible, just-in-time scheduling of map tasks, and not
require us to make any assumptions about how many (or which) nodes participate
in the map and reduce phases.

In this section, we'll assume that all shuffle data fits in memory (i.e. we
never hit disk); in later sections, we'll extend this to support on-disk
coalescing of shuffle outputs.  For brevity's sake, we'll present the
algorithm for multiple mappers and a single reducer; reducers operate on
disjoint partitions of data, so this approach generalizes to multiple reducers
by instantiating one instances of the algorithm per reducer.

At a high-level, our strategy will aggregate new map outputs into existing map
outputs from the same job that are stored on the same machine.  Reducers will
still issue requests for each individual map output, but in response they may
receive a regular map output, the combination of several map outputs, or a
small pointer with the address of the combined output that contains the
requested output's data.

At a high level, we can use the following strategy to combine a node's outputs:

\begin{minted}{scala}
def blockManagerMaster(message) {
   message match {
      CommitBlock(block_id) => {
         // For now, we'll implement a "first writer wins" policy
         // for shuffle blocks, where we only store the first copy.
         return isFirst(block_id)
      }
      GetBlockLocations(block_id) => {
         // ...
      }
   }
}

def blockManager(message) {
    message match {
        FetchBlock(block_id) => {
            synchronized (blockInfo(block_id)) {
                block.markRead()
                return block.data
            }
        }
    }
}

def mapTask(partitionId, data, isRecomputation) {
    // Produce the map outputs:
    mapOutput = f(data)
    blockName = "reduce_" + partitionId
    blockInfo = createLocalBlockInfo(blockName)
    synchronized (blockInfo) {  // Lock out readers
       // Commit the block, then decide how to aggregate it:
       ack = blockManagerMaster.send(CommitBlock(blockName))
       combinerBlock = LocalCombinerManager.getCombiner(stageId)
       if (!ack.isFirst) {
         // Another task already computed this block; discard it.
         return
       }
       if (combinerBlock != null && !combinerBlock.wasRead) {
            // Merge into the existing block:
            combinerBlock.accumulate(mapOutput)
            // Store a pointer to the aggregate:
            blockManager.put(AggregatePointer(blockName,
                                              combinerBlock.name))
       } else {
            // Store regularly, then mark as the new combiner block
            blockManager.put(blockName, mapOutput)
            combinerBlock =
               LocalCombinerManager.registerCombiner(stageId,
                                                     combinerBlock)
       }
    }
}

def reduceTask(partitionId) {
    blocksInAgg = {}
    missingBlocks = {}
    finalAggregate = new Aggregate()
    asynchronously fetch missingBlocks{ block =>
        block match {
            case AggregatePointer(id, target) =>
                blocksInAgg[target] += orig
                // Sanity check: if a pointer is received after the block
                // it references, the referenced block should contain data
                // from the partition that sent the pointer.
            case Aggregate(id, sourceBlocks, data) => {
                finalAggregate.add(data)
                // If the aggregate doesn't have the expected blocks,
                // re-fetch all of those blocks because we had a failure.
                if (sourceBlocks != blocksInAgg[block.id]) {
                   missing = blocksInAgg[block.id]
                   missingBlocks.add(blocksInAgg[block.id] - sourceBlocks)
                }
            }
            case RegularBlock(id, data) => {
                finalAggregate.add(data)
            }
        }
    }
}
\end{minted}

This algorithm handles several failure modes, some of which are subtle:

\begin{itemize}
   \item \textbf{Mapper failures during reduce:} If a mapper fails while
   reducers have fetched a subset of its outputs, we need to ensure that those
   reducers eventually re-request any missing blocks.  If a mapper fails after
   a reducer has received its pointers to aggregated blocks that haven't been
   fetched, the aggregated block will be marked as missing and recomputed.
   When it receives the recomputed block, the reducer will realize that its
   contents don't match the expected contents that were calculated from the
   pointers, causing the other missing blocks to be recomputed.

   Unfortunately, this adds some latency because the reducer doesn't
   re-request all of missing blocks as soon as the failure occurs.  We could
   address this problem by having the reducer immediately re-request a block's
   pointers if the block's fetch fails due to a crashed mapper.  This would be
   easy to express in an event-driven framework, where block requests return
   immediately with either ``fetch started'' or ``recomputation started''
   messages.

   \item \textbf{Aggregation of recomputed map outputs:} Since we always
   persist shuffle outputs on disk, shuffle outputs are only recomputed when
   mappers fail.  Our aggregation strategy only aggregates map outputs into
   blocks that have not yet been fetched by reducers.  If multiple map outputs
   are recomputed using the same machine, the recomputed tasks will share
   a new combiner block.

   \item \textbf{Speculative execution:} With speculative execution, multiple
   tasks could be racing to compute the same map output.  There aren't
   significant benefits to caching redundant copies of shuffle blocks, so our
   use of a commit protocol allows us to store only the first copy of a block.

  % Note: it's possible to extend the protocol to not throw away redundant
  % copies, since this gives us some limited fault-tolerance capability, but
  % the complexity doesn't seem justifiable:

  % This might be addressed by adding a 'commit' phase, where output's
  % availability is registered with the BlockManagerMaster before deciding
  % whether to combine it or not.  If a speculative task completes first, then
  % the original copy of that task won't aggregate its output with any other
  % blocks.

  % This doesn't address the opposite situation, where the speculative task
  % finishes second but the original task's output has already been saved.  We
  % could handle this case by still storing the speculative task, but under
  % a different name.  We would only need to access this block if the mapper
  % that ran the original mapper failed.  To handle this, we can add
  % special-case logic to the BlockManagerMaster to search for this block when
  % the last copy of a shuffle block is removed from its mapping; if the block
  % is found, we can rename it.

\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Pipelining}

This aggregation scheme can be extended to support a limited form of pipelined
reduce, where reducers can begin fetching outputs from completed mappers while
other mappers are still executing.  We simply add additional locking to ensure
that partial pre-aggregates become immutable once they have been read.  This
avoids problems where a completed map task aggregates its results into a block
that has already been fetched and that may not be re-requested unless
a reducer fails.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Spilling Shuffle Data to Disk}

We can employ similar strategies for spilling shuffle data to disk.  By
keeping shuffle outputs in memory, we should avoid hitting disk for shuffles
with many partitions and little data per partition (one of the
worst-performing cases in terms of bytes of data read per random access).  The
machine-local combining should also significantly reduce the shuffled data
volume.

Even though these techniques may mitigate most of the disk performance
bottlenecks, we still need to handle the case where we don't have enough
memory to hold all of the machine-local pre-aggregates.  In this case, we can
spill partial pre-aggregates to disk.  We can employ a similar ``indirection''
scheme, storing pointers such that the combined files on disk are requested
and processed similarly to how we process aggregates.

\textbf{TODO:} I haven't thought through disk-based strategies that much,
since I expect that with this type of pre-aggregation, the jobs that would
need to spill the partial aggregates to disk would either cause the reducers
to run out of memory when reading those aggregates, or would run out of memory
while constructing a hashtable in the mapper.  It may be worth revisiting this
    if we add more general ``graceful-degradation'' under memory pressure by
        using disk-spilling algorithms and data structures.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{plain}
\bibliography{aggregation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
